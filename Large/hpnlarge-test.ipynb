{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport time\nimport argparse\n\nimport os\nimport datetime\nimport torch.nn.functional as F\nimport random\n\nfrom torch.distributions.categorical import Categorical\nimport math\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.optim import lr_scheduler\nimport matplotlib.pyplot as plt\nimport time\nfrom tqdm import tqdm_notebook\nfrom tqdm import tqdm_notebook\nimport math\nimport numpy as np\nimport torch\nimport tqdm\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import distance\n# visualization \n%matplotlib inline\nfrom IPython.display import set_matplotlib_formats, clear_output\nimport matplotlib_inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats('png2x','pdf')\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\ndevice = torch.device(\"cpu\"); gpu_id = -1 # select CPU\n\ngpu_id = '0' # select a single GPU  \n#gpu_id = '2,3' # select multiple GPUs  \nos.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print('GPU name: {:s}, gpu_id: {:s}'.format(torch.cuda.get_device_name(0),gpu_id))   \n    \nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# HPN Large","metadata":{}},{"cell_type":"code","source":"def compute_tour_length(x, tour): \n    \"\"\"\n    Compute the length of a batch of tours\n    Inputs : x of size (bsz, nb_nodes, 2) batch of tsp tour instances\n             tour of size (bsz, nb_nodes) batch of sequences (node indices) of tsp tours\n    Output : L of size (bsz,)             batch of lengths of each tsp tour\n    \"\"\"\n    bsz = x.shape[0]\n    nb_nodes = x.shape[1]\n    arange_vec = torch.arange(bsz, device=x.device)\n    first_cities = x[arange_vec, tour[:,0], :] # size(first_cities)=(bsz,2)\n    previous_cities = first_cities\n    L = torch.zeros(bsz, device=x.device)\n    with torch.no_grad():\n        for i in range(1,nb_nodes):\n            current_cities = x[arange_vec, tour[:,i], :] \n            L += torch.sum( (current_cities - previous_cities)**2 , dim=1 )**0.5 # dist(current, previous node) \n            previous_cities = current_cities\n        L += torch.sum((current_cities - first_cities)**2 , dim=1)**0.5 # dist(last, first node)  \n    return L\n\nclass TransEncoderNet(nn.Module):\n    \"\"\"\n    Encoder network based on self-attention transformer\n    Inputs :  \n      h of size      (bsz, nb_nodes+1, dim_emb)    batch of input cities\n    Outputs :  \n      h of size      (bsz, nb_nodes+1, dim_emb)    batch of encoded cities\n      score of size  (bsz, nb_nodes+1, nb_nodes+1) batch of attention scores\n    \"\"\"\n    \n    def __init__(self, nb_layers, dim_emb, nb_heads, dim_ff, batchnorm):\n        super(TransEncoderNet, self).__init__()\n        assert dim_emb == nb_heads* (dim_emb//nb_heads) # check if dim_emb is divisible by nb_heads\n        self.MHA_layers = nn.ModuleList( [nn.MultiheadAttention(dim_emb, nb_heads) for _ in range(nb_layers)] )\n        self.linear1_layers = nn.ModuleList( [nn.Linear(dim_emb, dim_ff) for _ in range(nb_layers)] )\n        self.linear2_layers = nn.ModuleList( [nn.Linear(dim_ff, dim_emb) for _ in range(nb_layers)] )   \n        if batchnorm:\n            self.norm1_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n            self.norm2_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n        else:\n            self.norm1_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n            self.norm2_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n        self.nb_layers = nb_layers\n        self.nb_heads = nb_heads\n        self.batchnorm = batchnorm\n        \n    def forward(self, h):      \n        # PyTorch nn.MultiheadAttention requires input size (seq_len, bsz, dim_emb) \n        h = h.transpose(0,1) # size(h)=(nb_nodes, bsz, dim_emb)  \n        # L layers\n        for i in range(self.nb_layers):\n            h_rc = h # residual connection, size(h_rc)=(nb_nodes, bsz, dim_emb)\n            h, score = self.MHA_layers[i](h, h, h) # size(h)=(nb_nodes, bsz, dim_emb), size(score)=(bsz, nb_nodes, nb_nodes)\n            # add residual connection\n            \n            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n            if self.batchnorm:\n                # Pytorch nn.BatchNorm1d requires input size (bsz, dim, seq_len)\n                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n                h = self.norm1_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n            else:\n                h = self.norm1_layers[i](h)       # size(h)=(nb_nodes, bsz, dim_emb) \n            # feedforward\n            h_rc = h # residual connection\n            h = self.linear2_layers[i](torch.relu(self.linear1_layers[i](h)))\n            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n            if self.batchnorm:\n                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n                h = self.norm2_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n            else:\n                h = self.norm2_layers[i](h) # size(h)=(nb_nodes, bsz, dim_emb)\n        # Transpose h\n        h = h.transpose(0,1) # size(h)=(bsz, nb_nodes, dim_emb)\n        return h, score\n    \nclass Attention(nn.Module):\n    def __init__(self, n_hidden):\n        super(Attention, self).__init__()\n        self.size = 0\n        self.batch_size = 0\n        self.dim = n_hidden\n        \n        v  = torch.FloatTensor(n_hidden).cuda()\n        self.v  = nn.Parameter(v)\n        self.v.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n        \n        # parameters for pointer attention\n        self.Wref = nn.Linear(n_hidden, n_hidden)\n        self.Wq = nn.Linear(n_hidden, n_hidden)\n    \n    \n    def forward(self, q, ref):       # query and reference\n        self.batch_size = q.size(0)\n        self.size = int(ref.size(0) / self.batch_size)\n        q = self.Wq(q)     # (B, dim)\n        ref = self.Wref(ref)\n        ref = ref.view(self.batch_size, self.size, self.dim)  # (B, size, dim)\n        \n        q_ex = q.unsqueeze(1).repeat(1, self.size, 1) # (B, size, dim)\n        # v_view: (B, dim, 1)\n        v_view = self.v.unsqueeze(0).expand(self.batch_size, self.dim).unsqueeze(2)\n        \n        # (B, size, dim) * (B, dim, 1)\n        u = torch.bmm(torch.tanh(q_ex + ref), v_view).squeeze(2)\n        \n        return u, ref\n    \nclass LSTM(nn.Module):\n    def __init__(self, n_hidden):\n        super(LSTM, self).__init__()\n        \n        # parameters for input gate\n        self.Wxi = nn.Linear(n_hidden, n_hidden)    # W(xt)\n        self.Whi = nn.Linear(n_hidden, n_hidden)    # W(ht)\n        self.wci = nn.Linear(n_hidden, n_hidden)    # w(ct)\n        \n        # parameters for forget gate\n        self.Wxf = nn.Linear(n_hidden, n_hidden)    # W(xt)\n        self.Whf = nn.Linear(n_hidden, n_hidden)    # W(ht)\n        self.wcf = nn.Linear(n_hidden, n_hidden)    # w(ct)\n        \n        # parameters for cell gate\n        self.Wxc = nn.Linear(n_hidden, n_hidden)    # W(xt)\n        self.Whc = nn.Linear(n_hidden, n_hidden)    # W(ht)\n        \n        # parameters for forget gate\n        self.Wxo = nn.Linear(n_hidden, n_hidden)    # W(xt)\n        self.Who = nn.Linear(n_hidden, n_hidden)    # W(ht)\n        self.wco = nn.Linear(n_hidden, n_hidden)    # w(ct)\n    \n    \n    def forward(self, x, h, c):       # query and reference\n        \n        # input gate\n        i = torch.sigmoid(self.Wxi(x) + self.Whi(h) + self.wci(c))\n        # forget gate\n        f = torch.sigmoid(self.Wxf(x) + self.Whf(h) + self.wcf(c))\n        # cell gate\n        c = f * c + i * torch.tanh(self.Wxc(x) + self.Whc(h))\n        # output gate\n        o = torch.sigmoid(self.Wxo(x) + self.Who(h) + self.wco(c))\n        \n        h = o * torch.tanh(c)\n        \n        return h, c\n\nclass HPN(nn.Module):\n    def __init__(self, n_feature, n_hidden):\n\n        super(HPN, self).__init__()\n        self.city_size = 0\n        self.batch_size = 0\n        self.dim = n_hidden\n        \n        # pointer layer\n        self.pointer = Attention(n_hidden)\n        self.TransPointer = Attention(n_hidden)\n        \n        # lstm encoder\n        self.encoder = LSTM(n_hidden)\n        \n        # trainable first hidden input\n        h0 = torch.FloatTensor(n_hidden)\n        c0 = torch.FloatTensor(n_hidden)\n    \n        self.h0 = nn.Parameter(h0)\n        self.c0 = nn.Parameter(c0)\n        \n        self.h0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n        self.c0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n        \n        r1 = torch.ones(1)\n        r2 = torch.ones(1)\n        r3 = torch.ones(1)\n        \n        self.r1 = nn.Parameter(r1)\n        self.r2 = nn.Parameter(r2)\n        self.r3 = nn.Parameter(r3)\n        \n        # embedding\n        self.embedding_x = nn.Linear(n_feature, n_hidden)\n        self.embedding_all1 = nn.Linear(n_feature, n_hidden)\n        self.embedding_all2 = nn.Linear(n_feature + 1, n_hidden)\n        self.Transembedding_all = TransEncoderNet(6, 128, 8, 512, batchnorm=True)\n        \n        # vector to start decoding \n        self.start_placeholder = nn.Parameter(torch.randn(n_hidden))\n        \n        # weights for GNN\n        self.W1 = nn.Linear(n_hidden, n_hidden)\n        self.W2 = nn.Linear(n_hidden, n_hidden)\n        self.W3 = nn.Linear(n_hidden, n_hidden)\n        \n        # aggregation function for GNN\n        self.agg_1 = nn.Linear(n_hidden, n_hidden)\n        self.agg_2 = nn.Linear(n_hidden, n_hidden)\n        self.agg_3 = nn.Linear(n_hidden, n_hidden)\n    \n    \n    def forward(self, Transcontext, x, X_all, mask, h=None, c=None, latent=None):\n        '''\n        Inputs (B: batch size, size: city size, dim: hidden dimension)\n        \n        x: current city coordinate (B, 2)\n        X_all: all cities' cooridnates (B, size, 2)\n        mask: mask visited cities\n        h: hidden variable (B, dim)\n        c: cell gate (B, dim)\n        latent: latent pointer vector from previous layer (B, size, dim)\n        \n        Outputs\n        \n        softmax: probability distribution of next city (B, size)\n        h: hidden variable (B, dim)\n        c: cell gate (B, dim)\n        latent_u: latent pointer vector for next layer\n        '''\n        \n        self.batch_size = X_all.size(0)\n        self.city_size = X_all.size(1)\n        \n        # Check if this iteration is the first one\n        if h is None or c is None:\n            # Letting the placeholder be the first input\n            x          = self.start_placeholder\n            #  init-embedding for All Cities\n            context = self.embedding_all1(X_all)\n            # Transormer context \n            Transcontext,_ = self.Transembedding_all(context)\n            \n            Transcontext = Transcontext.reshape(-1, self.dim) # (B, size, dim)\n            \n            # =============================\n            # handling the cell and the hidden state for the first iteration \n            # =============================\n            h0 = self.h0.unsqueeze(0).expand(self.batch_size, self.dim)\n            c0 = self.c0.unsqueeze(0).expand(self.batch_size, self.dim)\n            h0 = h0.unsqueeze(0).contiguous()\n            c0 = c0.unsqueeze(0).contiguous()\n            # let h0, c0 be the hidden variable of first turn\n            h = h0.squeeze(0)\n            c = c0.squeeze(0)\n        else:\n            # =============================\n            # Feature context\n            # =============================\n            X_all      = torch.cat((torch.cdist(X_all,x.view(self.batch_size,1,2),p=2), X_all - x.unsqueeze(1).repeat(1, self.city_size, 1)), 2)\n            # sequential input Embedding \n            x          = self.embedding_x(x)\n            #  init-embedding for All Cities\n            context = self.embedding_all2(X_all)\n            \n        # =============================\n        # graph neural network encoder\n        # =============================\n        # Handling contextes's size\n        context = context.reshape(-1, self.dim)           # (B, size, dim)\n        context = self.r1 * self.W1(context) + (1-self.r1) * F.relu(self.agg_1(context/(self.city_size-1)))\n        context = self.r2 * self.W2(context) + (1-self.r2) * F.relu(self.agg_2(context/(self.city_size-1)))\n        context = self.r3 * self.W3(context) + (1-self.r3) * F.relu(self.agg_3(context/(self.city_size-1)))\n        # LSTM encoder\n        h, c = self.encoder(x, h, c)\n        \n        # =============================\n        # Decoding Phase\n        # ============================= \n        \n        u1, _ = self.pointer(h, context)\n        u2 ,_ = self.TransPointer(h,Transcontext)\n        u = u1 + u2\n        latent_u = u.clone()\n        u = 100 * torch.tanh(u) + mask\n        return Transcontext,F.softmax(u, dim=1), h, c, latent_u","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load HPN","metadata":{}},{"cell_type":"code","source":"Critic = HPN(n_feature=2, n_hidden=128)\nCritic = Critic.to(device)\nCritic.eval()\n\n#********************************************# Uncomment these lines to re-start training with saved checkpoint #********************************************#\n\ncheckpoint_file = \"../input/test-1-128641e3optstep/checkpoint_21-08-09--10-54-32-n50-gpu011Epochs.pkl\"\ncheckpoint = torch.load(checkpoint_file, map_location=device)\nepoch_ckpt = checkpoint['epoch'] + 1\ntot_time_ckpt = checkpoint['tot_time']\nplot_performance_train = checkpoint['plot_performance_train']\nplot_performance_baseline = checkpoint['plot_performance_baseline']\nCritic.load_state_dict(checkpoint['model_baseline'])\n\nprint('Re-start training with saved checkpoint file={:s}\\n  Checkpoint at epoch= {:d} and time={:.3f}min\\n'.format(checkpoint_file,epoch_ckpt-1,tot_time_ckpt/60))\ndel checkpoint\n\n#*********************************************# Uncomment these lines to re-start training with saved checkpoint #********************************************#","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Batch","metadata":{}},{"cell_type":"markdown","source":"## HPN Without 2opt","metadata":{}},{"cell_type":"code","source":"B = 50\n\ntotal_tour_len = 0\nn_test = int(1000/B)\n\n# there are 1000 test data\nsize = 250\nZ = torch.rand(n_test, B, size, 2).clone()\n\n\nfor m in tqdm_notebook(range(n_test)):\n    X = Z[m].cuda()\n    \n    mask = torch.zeros(B,size).cuda()\n    \n    R = 0\n    solution = []\n    reward = 0\n    \n    Y = X.view(B, size, 2)           # to the same batch size\n    x = Y[:,0,:]\n    h = None\n    c = None\n    Transcontext = None\n    for k in range(size):\n        Transcontext,output, h, c, _ = Critic(Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n        \n        idx = torch.argmax(output, dim=1)\n        \n        x = Y[[i for i in range(B)], idx.data]\n        solution.append(x.cpu().numpy())\n        \n        mask[[i for i in range(B)], idx.data] += -np.inf\n    \n    solution.append(solution[0])\n    graph = np.array(solution)\n    route = [x for x in range(size)] + [0]\n\n\n    for b in range(B):\n        best = route.copy()\n        # begin 2-opt\n        graph_ = graph[:,b,:].copy()\n            \n        dmatrix = distance.cdist(graph_, graph_, 'euclidean')\n        improved = True\n        '''\n        while improved:\n            improved = False\n            \n            for i in range(size):\n                for j in range(i+2, size+1):\n                    \n                    old_dist = dmatrix[best[i],best[i+1]] + dmatrix[best[j], best[j-1]]\n                    new_dist = dmatrix[best[j],best[i+1]] + dmatrix[best[i], best[j-1]]\n                    \n                    # new_dist = 1000\n                    if new_dist < old_dist:\n                        best[i+1:j] = best[j-1:i:-1]\n                        # print(opt_tour)\n                        improved = True\n        '''\n        new_tour_len = 0\n        for k in range(size):\n            new_tour_len += dmatrix[best[k], best[k+1]]\n\n        \n        total_tour_len += new_tour_len\n    print(\"sample:{}, new route length:{}\".format(m, new_tour_len))\n    \nprint('total length:', total_tour_len/1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## HPN With 2opt","metadata":{}},{"cell_type":"code","source":"B = 50\n\ntotal_tour_len = 0\nn_test = int(1000/B)\n\n# there are 1000 test data\nsize = 250\nZ = torch.rand(n_test, B, size, 2).clone()\n\n\nfor m in tqdm_notebook(range(n_test)):\n    X = Z[m].cuda()\n    \n    mask = torch.zeros(B,size).cuda()\n    \n    R = 0\n    solution = []\n    reward = 0\n    \n    Y = X.view(B, size, 2)           # to the same batch size\n    x = Y[:,0,:]\n    h = None\n    c = None\n    Transcontext = None\n    for k in range(size):\n        Transcontext,output, h, c, _ = Critic(Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n        \n        idx = torch.argmax(output, dim=1)\n        \n        x = Y[[i for i in range(B)], idx.data]\n        solution.append(x.cpu().numpy())\n        \n        mask[[i for i in range(B)], idx.data] += -np.inf\n    \n    solution.append(solution[0])\n    graph = np.array(solution)\n    route = [x for x in range(size)] + [0]\n\n\n    for b in range(B):\n        best = route.copy()\n        # begin 2-opt\n        graph_ = graph[:,b,:].copy()\n            \n        dmatrix = distance.cdist(graph_, graph_, 'euclidean')\n        improved = True\n        \n        while improved:\n            improved = False\n            \n            for i in range(size):\n                for j in range(i+2, size+1):\n                    \n                    old_dist = dmatrix[best[i],best[i+1]] + dmatrix[best[j], best[j-1]]\n                    new_dist = dmatrix[best[j],best[i+1]] + dmatrix[best[i], best[j-1]]\n                    \n                    # new_dist = 1000\n                    if new_dist < old_dist:\n                        best[i+1:j] = best[j-1:i:-1]\n                        # print(opt_tour)\n                        improved = True\n        \n        new_tour_len = 0\n        for k in range(size):\n            new_tour_len += dmatrix[best[k], best[k+1]]\n\n        \n        total_tour_len += new_tour_len\n    print(\"sample:{}, new route length:{}\".format(m, new_tour_len))\n    \nprint('total length:', total_tour_len/1000)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data pre-processing For benchmark Instances ","metadata":{}},{"cell_type":"code","source":"# Data path\ndata_path='../input/pa561data/pa561.tsp'\ndata = np.loadtxt(data_path,dtype='float32')\n\n# Delete the labeling col from the file\ndata = np.delete(data, 0, axis=1)\nsize = data.shape[0]\ntest_data = torch.from_numpy(data)\ndata2=torch.zeros(size,2)\n\n# normalize data \nmin = torch.min(test_data,0)\nmax = torch.max(test_data,0)\ndata2[:,0] = (test_data[:,0] - min[0][0]) / (max[0][0]-min[0][0])\ndata2[:,1] = (test_data[:,1] - min[0][1]) / (max[0][1]-min[0][1])\n\nZ = data2.view(1,1, size, 2).to(device)\nZ.required_grad = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Without 2opt","metadata":{}},{"cell_type":"code","source":"start = time.time()\ntotal_tour_len = 0\nn_test = 1\nB = 1\nwith torch.no_grad():\n    for m in tqdm.notebook.tqdm(range(n_test)):\n        X = Z[m].cuda()\n        mask = torch.zeros(B,size).cuda()\n        R = 0\n        solution = []\n        solution_real = []\n        reward = 0\n        Y = X.view(B, size, 2)           # to the same batch size\n        test_data = test_data.view(B,size,2)\n        x = Y[:,0,:]\n        h = None\n        c = None\n        Transcontext = None\n        for k in range(size):\n            Transcontext,output, h, c, _ = Critic(Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n            idx = torch.argmax(output, dim=1)\n            x      = Y[[i for i in range(B)], idx.data]\n            x_real = test_data[[i for i in range(B)], idx.data]\n            solution.append(x.cpu().numpy())\n            solution_real.append(x_real.cpu().numpy())\n            mask[[i for i in range(B)], idx.data] += -np.inf\n        solution.append(solution[0])\n        graph = np.array(solution)\n        graph_real = np.array(solution_real)\n        route = [x for x in range(size)] + [0]\n        for b in range(B):\n            best = route.copy()\n            # begin 2-opt\n            graph_ = graph[:,b,:].copy()\n            dmatrix = distance.cdist(graph_, graph_, 'euclidean')\n            improved = True\n            \"\"\"\n            while improved:\n                improved = False\n                for i in range(size):\n                    for j in range(i+2, size+1):\n                        old_dist = dmatrix[best[i],best[i+1]] + dmatrix[best[j], best[j-1]]\n                        new_dist = dmatrix[best[j],best[i+1]] + dmatrix[best[i], best[j-1]]\n                        if new_dist < old_dist:\n                            best[i+1:j] = best[j-1:i:-1]\n                            improved = True\n                            \n            \"\"\" \n            new_tour_len = 0\n            for k in range(size):\n                new_tour_len += dmatrix[best[k], best[k+1]]\n            total_tour_len += new_tour_len\n        print(\"sample:{}, new route length:{}\".format(m, new_tour_len))\n    print('total length:', total_tour_len)\n    print('tot time',time.time() - start)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## With 2opt","metadata":{}},{"cell_type":"code","source":"start = time.time()\ntotal_tour_len = 0\nwith torch.no_grad():\n    for m in tqdm.notebook.tqdm(range(n_test)):\n        X = Z[m].cuda()\n        mask = torch.zeros(B,size).cuda()\n        R = 0\n        solution = []\n        solution_real = []\n        reward = 0\n        Y = X.view(B, size, 2)           # to the same batch size\n        test_data = test_data.view(B,size,2)\n        x = Y[:,0,:]\n        h = None\n        c = None\n        Transcontext = None\n        for k in range(size):\n            Transcontext,output, h, c, _ = Critic(Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n            idx = torch.argmax(output, dim=1)\n            x      = Y[[i for i in range(B)], idx.data]\n            x_real = test_data[[i for i in range(B)], idx.data]\n            solution.append(x.cpu().numpy())\n            solution_real.append(x_real.cpu().numpy())\n            mask[[i for i in range(B)], idx.data] += -np.inf\n        solution.append(solution[0])\n        graph = np.array(solution)\n        graph_real = np.array(solution_real)\n        route = [x for x in range(size)] + [0]\n        for b in range(B):\n            best = route.copy()\n            # begin 2-opt\n            graph_ = graph[:,b,:].copy()\n            dmatrix = distance.cdist(graph_, graph_, 'euclidean')\n            improved = True\n            while improved:\n                improved = False\n                for i in range(size):\n                    for j in range(i+2, size+1):\n                        old_dist = dmatrix[best[i],best[i+1]] + dmatrix[best[j], best[j-1]]\n                        new_dist = dmatrix[best[j],best[i+1]] + dmatrix[best[i], best[j-1]]\n                        if new_dist < old_dist:\n                            best[i+1:j] = best[j-1:i:-1]\n                            improved = True\n            new_tour_len = 0\n            for k in range(size):\n                new_tour_len += dmatrix[best[k], best[k+1]]\n            total_tour_len += new_tour_len\n        print(\"sample:{}, new route length:{}\".format(m, new_tour_len))\n    print('total length:', total_tour_len)\n    print('tot time',time.time() - start)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Unnormalized distance","metadata":{}},{"cell_type":"code","source":"graph_real = torch.tensor(graph_real,dtype = torch.float64).squeeze(1).unsqueeze(0)\nL = compute_tour_length(graph_real,torch.tensor(best).unsqueeze(0))\nprint(L)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple visualization","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nTSP = np.zeros([size+1,2],dtype=np.float32)\nfor i in range(TSP.shape[0]):\n    idx = best[i]\n    TSP[i] = graph_[idx,:]\n\nfig = plt.figure(figsize=(10,10))\nplt.scatter(TSP[:,0],TSP[:,1],s = 10)\nplt.plot(TSP[:,0],TSP[:,1])\n#Saving the plot as an image\nfig.savefig('ei8246.jpg', bbox_inches='tight', dpi=150)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}