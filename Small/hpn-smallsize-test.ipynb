{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport time\nimport argparse\n\nimport os\nimport datetime\n\nfrom torch.distributions.categorical import Categorical\n\n# visualization \n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\ndevice = torch.device(\"cpu\"); gpu_id = -1 # select CPU\n\ngpu_id = '0' # select a single GPU  \n#gpu_id = '2,3' # select multiple GPUs  \nos.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print('GPU name: {:s}, gpu_id: {:s}'.format(torch.cuda.get_device_name(0),gpu_id))   \n    \nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-18T05:34:42.569774Z","iopub.execute_input":"2021-09-18T05:34:42.570231Z","iopub.status.idle":"2021-09-18T05:34:47.087975Z","shell.execute_reply.started":"2021-09-18T05:34:42.570113Z","shell.execute_reply":"2021-09-18T05:34:47.087258Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"GPU name: Tesla P100-PCIE-16GB, gpu_id: 0\ncuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model's Components","metadata":{}},{"cell_type":"code","source":"import math\nimport numpy as np\nimport torch.nn.functional as F\nimport random\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.optim import lr_scheduler\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\n\nclass TransEncoderNet(nn.Module):\n    \"\"\"\n    Encoder network based on self-attention transformer\n    Inputs :  \n      h of size      (bsz, nb_nodes, dim_emb)    batch of input cities\n    Outputs :  \n      h of size      (bsz, nb_nodes, dim_emb)    batch of encoded cities\n      score of size  (bsz, nb_nodes, nb_nodes+1) batch of attention scores\n    \"\"\"\n    \n    def __init__(self, nb_layers, dim_emb, nb_heads, dim_ff, batchnorm):\n        super(TransEncoderNet, self).__init__()\n        assert dim_emb == nb_heads* (dim_emb//nb_heads) # check if dim_emb is divisible by nb_heads\n        self.MHA_layers = nn.ModuleList( [nn.MultiheadAttention(dim_emb, nb_heads) for _ in range(nb_layers)] )\n        self.linear1_layers = nn.ModuleList( [nn.Linear(dim_emb, dim_ff) for _ in range(nb_layers)] )\n        self.linear2_layers = nn.ModuleList( [nn.Linear(dim_ff, dim_emb) for _ in range(nb_layers)] )   \n        if batchnorm:\n            self.norm1_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n            self.norm2_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n        else:\n            self.norm1_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n            self.norm2_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n        self.nb_layers = nb_layers\n        self.nb_heads = nb_heads\n        self.batchnorm = batchnorm\n        \n    def forward(self, h):      \n        # PyTorch nn.MultiheadAttention requires input size (seq_len, bsz, dim_emb) \n        h = h.transpose(0,1) # size(h)=(nb_nodes, bsz, dim_emb)  \n        # L layers\n        for i in range(self.nb_layers):\n            h_rc = h # residual connection, size(h_rc)=(nb_nodes, bsz, dim_emb)\n            h, score = self.MHA_layers[i](h, h, h) # size(h)=(nb_nodes, bsz, dim_emb), size(score)=(bsz, nb_nodes, nb_nodes)\n            # add residual connection\n            \n            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n            if self.batchnorm:\n                # Pytorch nn.BatchNorm1d requires input size (bsz, dim, seq_len)\n                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n                h = self.norm1_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n            else:\n                h = self.norm1_layers[i](h)       # size(h)=(nb_nodes, bsz, dim_emb) \n            # feedforward\n            h_rc = h # residual connection\n            h = self.linear2_layers[i](torch.relu(self.linear1_layers[i](h)))\n            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n            if self.batchnorm:\n                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n                h = self.norm2_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n            else:\n                h = self.norm2_layers[i](h) # size(h)=(nb_nodes, bsz, dim_emb)\n        # Transpose h\n        h = h.transpose(0,1) # size(h)=(bsz, nb_nodes, dim_emb)\n        return h, score\n    \n\nclass Attention(nn.Module):\n    def __init__(self, n_hidden):\n        super(Attention, self).__init__()\n        self.size = 0\n        self.batch_size = 0\n        self.dim = n_hidden\n        \n        v  = torch.FloatTensor(n_hidden)\n        self.v  = nn.Parameter(v)\n        self.v.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n        \n        # parameters for pointer attention\n        self.Wref = nn.Linear(n_hidden, n_hidden)\n        self.Wq = nn.Linear(n_hidden, n_hidden)\n    \n    \n    def forward(self, q, ref):       # query and reference\n        self.batch_size = q.size(0)\n        self.size = int(ref.size(0) / self.batch_size)\n        q = self.Wq(q)     # (B, dim)\n        ref = self.Wref(ref)\n        ref = ref.view(self.batch_size, self.size, self.dim)  # (B, size, dim)\n        \n        q_ex = q.unsqueeze(1).repeat(1, self.size, 1) # (B, size, dim)\n        # v_view: (B, dim, 1)\n        v_view = self.v.unsqueeze(0).expand(self.batch_size, self.dim).unsqueeze(2)\n        \n        # (B, size, dim) * (B, dim, 1)\n        u = torch.bmm(torch.tanh(q_ex + ref), v_view).squeeze(2)\n        \n        return u, ref\n    \nclass LSTM(nn.Module):\n    def __init__(self, n_hidden):\n        super(LSTM, self).__init__()\n        \n        # parameters for input gate\n        self.Wxi = nn.Linear(n_hidden, n_hidden)    # W(xt)\n        self.Whi = nn.Linear(n_hidden, n_hidden)    # W(ht)\n        self.wci = nn.Linear(n_hidden, n_hidden)    # w(ct)\n        \n        # parameters for forget gate\n        self.Wxf = nn.Linear(n_hidden, n_hidden)    # W(xt)\n        self.Whf = nn.Linear(n_hidden, n_hidden)    # W(ht)\n        self.wcf = nn.Linear(n_hidden, n_hidden)    # w(ct)\n        \n        # parameters for cell gate\n        self.Wxc = nn.Linear(n_hidden, n_hidden)    # W(xt)\n        self.Whc = nn.Linear(n_hidden, n_hidden)    # W(ht)\n        \n        # parameters for forget gate\n        self.Wxo = nn.Linear(n_hidden, n_hidden)    # W(xt)\n        self.Who = nn.Linear(n_hidden, n_hidden)    # W(ht)\n        self.wco = nn.Linear(n_hidden, n_hidden)    # w(ct)\n    \n    \n    def forward(self, x, h, c):       # query and reference\n        \n        # input gate\n        i = torch.sigmoid(self.Wxi(x) + self.Whi(h) + self.wci(c))\n        # forget gate\n        f = torch.sigmoid(self.Wxf(x) + self.Whf(h) + self.wcf(c))\n        # cell gate\n        c = f * c + i * torch.tanh(self.Wxc(x) + self.Whc(h))\n        # output gate\n        o = torch.sigmoid(self.Wxo(x) + self.Who(h) + self.wco(c))\n        \n        h = o * torch.tanh(c)\n        \n        return h, c\n\nclass HPN(nn.Module):\n    def __init__(self, n_feature, n_hidden):\n\n        super(HPN, self).__init__()\n        self.city_size = 0\n        self.batch_size = 0\n        self.dim = n_hidden\n        \n        # lstm for first turn\n        #self.lstm0 = nn.LSTM(n_hidden, n_hidden)\n        \n        # pointer layer\n        self.pointer = Attention(n_hidden)\n        self.TransPointer = Attention(n_hidden)\n        \n        # lstm encoder\n        self.encoder = LSTM(n_hidden)\n        \n        # trainable first hidden input\n        h0 = torch.FloatTensor(n_hidden)\n        c0 = torch.FloatTensor(n_hidden)\n        \n        # trainable latent variable coefficient\n        alpha = torch.ones(1).cuda()\n        \n        self.h0 = nn.Parameter(h0)\n        self.c0 = nn.Parameter(c0)\n        \n        self.alpha = nn.Parameter(alpha)\n        self.h0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n        self.c0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n        \n        r1 = torch.ones(1)\n        r2 = torch.ones(1)\n        r3 = torch.ones(1)\n        self.r1 = nn.Parameter(r1)\n        self.r2 = nn.Parameter(r2)\n        self.r3 = nn.Parameter(r3)\n        \n        # embedding\n        self.embedding_x = nn.Linear(n_feature, n_hidden)\n        self.embedding_all = nn.Linear(n_feature, n_hidden)\n        self.Transembedding_all = TransEncoderNet(6, 128, 8, 512, batchnorm=True)\n        \n        # vector to start decoding \n        self.start_placeholder = nn.Parameter(torch.randn(n_hidden))\n        \n        # weights for GNN\n        self.W1 = nn.Linear(n_hidden, n_hidden)\n        self.W2 = nn.Linear(n_hidden, n_hidden)\n        self.W3 = nn.Linear(n_hidden, n_hidden)\n        \n        # aggregation function for GNN\n        self.agg_1 = nn.Linear(n_hidden, n_hidden)\n        self.agg_2 = nn.Linear(n_hidden, n_hidden)\n        self.agg_3 = nn.Linear(n_hidden, n_hidden)\n    \n    \n    def forward(self,context,Transcontext, x, X_all, mask, h=None, c=None, latent=None):\n        '''\n        Inputs (B: batch size, size: city size, dim: hidden dimension)\n        \n        x: current city coordinate (B, 2)\n        X_all: all cities' cooridnates (B, size, 2)\n        mask: mask visited cities\n        h: hidden variable (B, dim)\n        c: cell gate (B, dim)\n        latent: latent pointer vector from previous layer (B, size, dim)\n        \n        Outputs\n        \n        softmax: probability distribution of next city (B, size)\n        h: hidden variable (B, dim)\n        c: cell gate (B, dim)\n        latent_u: latent pointer vector for next layer\n        '''\n        \n        self.batch_size = X_all.size(0)\n        self.city_size = X_all.size(1)\n        \n        # Check if this the first iteration loop\n        if h is None or c is None:\n            x          = self.start_placeholder    \n            context = self.embedding_all(X_all)\n            Transcontext,_ = self.Transembedding_all(context)\n            \n            # =============================\n            # graph neural network encoder\n            # =============================\n\n            # (B, size, dim)\n            context = context.reshape(-1, self.dim)\n            Transcontext = Transcontext.reshape(-1, self.dim)\n\n            context = self.r1 * self.W1(context)\\\n                + (1-self.r1) * F.relu(self.agg_1(context/(self.city_size-1)))\n\n            context = self.r2 * self.W2(context)\\\n                + (1-self.r2) * F.relu(self.agg_2(context/(self.city_size-1)))\n\n            context = self.r3 * self.W3(context)\\\n                + (1-self.r3) * F.relu(self.agg_3(context/(self.city_size-1)))\n            h0 = self.h0.unsqueeze(0).expand(self.batch_size, self.dim)\n            c0 = self.c0.unsqueeze(0).expand(self.batch_size, self.dim)\n\n            h0 = h0.unsqueeze(0).contiguous()\n            c0 = c0.unsqueeze(0).contiguous()\n            \n            # let h0, c0 be the hidden variable of first turn\n            h = h0.squeeze(0)\n            c = c0.squeeze(0)\n        else:\n            x          = self.embedding_x(x)\n        # LSTM encoder\n        h, c = self.encoder(x, h, c)\n        # query vector\n        q = h\n        # pointer\n        u1, _ = self.pointer(q, context)\n        u2 ,_ = self.TransPointer(q,Transcontext)\n        \n        # Summing the two attention vectors\n        u = u1 + u2\n        latent_u = u.clone()\n        u = 10 * torch.tanh(u) + mask\n        return context,Transcontext,F.softmax(u, dim=1), h, c, latent_u","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:34:47.089504Z","iopub.execute_input":"2021-09-18T05:34:47.089749Z","iopub.status.idle":"2021-09-18T05:34:47.141570Z","shell.execute_reply.started":"2021-09-18T05:34:47.089715Z","shell.execute_reply":"2021-09-18T05:34:47.140805Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# TEST","metadata":{}},{"cell_type":"code","source":"###################\n# Instantiate a training network and a baseline network\n###################\nCritic = HPN(n_feature=2, n_hidden=128).to(device)\nCritic.eval()\n\n#********************************************# Uncomment these lines to re-start training with saved checkpoint #********************************************#\ncheckpoint_file = \"../input/tsp50beamsearch/checkpoint_21-09-03--20-13-13-n50-gpu0.pkl\"\ncheckpoint = torch.load(checkpoint_file, map_location=device)\nCritic.load_state_dict(checkpoint['model_baseline'])\ndel checkpoint\n#*********************************************# Uncomment these lines to re-start training with saved checkpoint #********************************************#\nCheckpoint = True\n#Checkpoint = False\n\nB_val = 10000\nsize_val = 50\n\nif Checkpoint:\n    X = torch.load('../input/tsp50beamsearch/10k_TSP50.pt').to(device)\nelse:\n    X = torch.rand(B_val,size_val,2, device = device)\n    \nwith torch.no_grad():\n    # greedy validation\n    tour_len = 0\n    zero_to_bsz = torch.arange(B_val, device = device) # [0,1,...,bsz-1]\n    mask = torch.zeros(B_val,size_val).cuda()\n    R = 0\n    reward = 0\n    Y = X.view(B_val, size_val, 2)    # to the same batch size\n    x = Y[:,0,:]\n    h = None\n    c = None\n    context = None\n    Transcontext = None\n    for k in range(size_val):\n        context,Transcontext,output, h, c, _ = Critic(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n        idx = torch.argmax(output, dim=1)\n        Y1 = Y[zero_to_bsz, idx.data]\n        if k == 0:\n            Y_ini = Y1.clone()\n        if k > 0:\n            #reward = torch.linalg.norm(Y1-Y0, dim=1)\n            reward  = torch.sum((Y1 - Y0)**2 , dim=1 )**0.5\n        Y0 = Y1.clone()\n        x = Y[zero_to_bsz, idx.data]\n        R += reward\n        mask[zero_to_bsz, idx.data] += -np.inf\n\n    #R += torch.linalg.norm(Y1-Y_ini, dim=1)\n    R  += torch.sum((Y1 - Y_ini)**2 , dim=1 )**0.5\n    tour_len += R.mean().item()\n    print('validation tour length:', tour_len)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:36:47.763808Z","iopub.execute_input":"2021-09-18T05:36:47.764122Z","iopub.status.idle":"2021-09-18T05:36:49.771983Z","shell.execute_reply.started":"2021-09-18T05:36:47.764092Z","shell.execute_reply":"2021-09-18T05:36:49.771260Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"validation tour length: 5.706809997558594\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}